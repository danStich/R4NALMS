```{r, child="_styles.Rmd"}
```

---
title: "Applications of R for Aquatic Plant Data"
---

<img src="./images/roh.png" alt="">

Welcome Applications of R for Aquatic Plant data! This module will serve as a tutorial to help you understand how to improve your data and analysis workflows for aquatic plant data in R. 

**This Site is Currently Under Construction** We are working on updating this page with a brand-new, whiz-bang module about aquatic plant data! We'll be in touch with workshop attendees once it is ready.

## Libraries
Let's go ahead and load the libraries we'll be working with in the first half of this workshop.
```{r}
library(tidyverse)
```

## Data
The first data set we'll work with is from a point-intercept (rake-toss) survey in Otsego Lake, NY, USA during summer 2025. Well...sort of. 

The original data were collected by Chii Kojima, an undergraduate at Mt. Holyoke College and SUNY Oneonta BFS summer intern, and Mairi Meehan, a professor at SUNY Cobleskill and BFS visiting faculty researcher. They completed 3 surveys at 54 points throughout the growing season on the dates included in the data set, with three rake tosses at each site. They recorded `Depth`, location (`Longitude` and `Latitude`), and categorical abundance (`Z`, `T`, `S`, `M`, or `D`) of each species at each site. If you are not familiar with this categorical abundance scale, the letters represent Zero, Trace, Sparse, Moderate, and Dense. They wanted to understand seasonality in plant presence and abundance and whether this and other factors could be used to improve survey design for long-term monitoring.

We used the original data to simulate new data using an institutional large language model (LLM, "AI") to simulate new observations at sites and dates from the survey based on spatial and temporal autocorrelation in the data, with depth as a covariate of abundance, and with permission for all of this from the data originators. As an aside, this was a fun learning experience and the AI ended up using the same methods we would have employed, but ironically it used Python instead of R. And, it did a pretty not bad job of simulating the new data set that we'll play with. Back on track here.

Read in the simulated data now that we are done with story time:

```{r}
plants <- read.csv("data/plant_abundances.csv")
```

Have a look at the data set using `glimpse()`, as shown below, or you can look at it in data table format using `View()`. We're not showing the output here in our version because it's a bit long.

```{r, eval=FALSE}
glimpse(plants)
```

This is a pretty standard point-intercept data set. It is in a somewhat "wide" format. That is, plant species are in columns to the right of all the other aggregated site and event data. The wide format is good for data entry and viewing in spreadsheets, but it is not how we'll want the data formatted for *most* of our needs in R.

We'll first need to get the data set into a longer format to work with it more easily for most uses in R. This would be a bit of a copy-paste nightmare in your typical spreadsheet application. But, it is very easily done using the `pivot_longer()` function from the `dplyr` package. We're telling R to stack the individual columns for species `8:ncol(plants)` into two columns: one with species name, and one with categorical abundance. You would need to change this for a different data set, but could also do things like identify columns with underscore characters (`_`) if your species columns were named similarly.
```{r}
long_data <- pivot_longer(plants,
                          cols = 8:ncol(plants),
                          names_to = "Species",
                          values_to = "Abundance")
```

## Presence-absence data
First, we'll look at how we can work with information about presences and absences of plants at each site on each survey to say something about the plant community. Some common tools for assessing plant communities might include metrics such as species richness or evenness.

To start with, we'll need to make a new column for presence-absence data so we can do things like add up species. There are a few different ways to do this. A succinct approach would be to initialize a new column that is all zeroes and then replace any zeroes with ones if the `Abundance` column contained anything other than `Z`. Like this:
```{r}
# Initialize new column called Presence of all `0`s
long_data$Presence <- 0

# Change this to `1` if Abundance does not equal `Z` for zero
long_data$Presence[long_data$Abundance != "Z"] <- 1

```

We could look at the presence absence data in a few different ways. First, let's estimate species richness for each `Site` and `Survey` using the replicate observations (`Toss`). We're also keeping columns for `Longitude` and `Latitude` here so we can play with those below.

```{r, message=FALSE, warning = FALSE}
richness <- long_data %>% 
  group_by(Site, Survey, Longitude, Latitude) %>% 
  summarize(Richness = sum(Presence))
```

Now we can make a boxplot to visualize richness across surveys (June, July, August) to see if there are obvious seasonal trends.

```{r}
ggplot(richness, aes(x = Survey, y = Richness, group = Survey)) +
  geom_boxplot()
```

This is cool, but you could spend some time to make it a little prettier. It looks like there is an increase from June through the later months, but it's not super clear whether survey `2` and `3` differed from one another.

You could formally test for differences among groups using a variety of approaches.

## Temporal trends in species richness
The simplest approach, free of distributional assumptions and a lot of other potential statistical pitfalls, would be to use a non-parametric Kruskal-Wallis test to determine whether there were significant differences in Richness among surveys.
```{r}
kruskal.test(Richness ~ Survey, data = richness)
```

This tells us that there were differences among surveys, but it doesn't give us any statistical information about how richness differed among sites. For that you'd need to use some kind of pairwise comparison like the pairwise Wilcox test. Usually these tests have some kind of adjustment to account for increased Type-I error rate. Here we use a Bonferroni adjustment for p-values, although we are not advocating specifically for that approach (there are a bunch).

```{r}
pairwise.wilcox.test(x = richness$Richness, g = richness$Survey, p.adjust.method = "bonferroni")
```

This output shows that richness differed significantly between `Survey 1` and `Survey 2` (p < 0.001), and `Survey 1` and `Survey 3` (p < 0.001), but we failed to detect a difference in `Richness` between `Survey 2` and `Survey 3` (p = 1). We could fall back on the boxplot we made above to report these results.

At some point, you'd probably want to account for the fact that species richness observations are based on multiple sites and locations, either by incorporating that into statistical tests directly or as a "random effect" in more complex models.

## Spatial trends in species richness
We could also use R to investigate spatial trends in species richness. This requires a little more in-depth knowledge about statistics and modeling, but it is still pretty straightforward to do in R. This type of question is very approachable through use of generalized linear models that include everything from ANOVA, linear regression, and analysis of covariance (ANCOVA) to logistic regression and count models. And, these modeling tools are easy to use in R (maybe too easy) as long as you have a functional understanding of them. 

For example, we could use the `glm()` function to examine spatial and temporal patterns in species richness pretty easily. We use a Poisson count model below to demonstrate what this could look like. 
```{r}
richness_mod <- glm(Richness ~ Longitude*Latitude + factor(Survey), 
                    data = richness, 
                    family = poisson)

summary(richness_mod)
```
We could check out the residuals to see whether we are in extreme violation of distributional assumptions. These plots show that the model residuals are more-or-less symmetrical, which aligns with assumptions of the Poissson distribution. There are a few zeroes in the earliest survey that are expressed as a peak around -1 for survey 1 in the plot below. If this was a larger proportion we'd have to be careful about assessing their influence, and may opt for an alternative approach, but this will suffice for the rest of our example for now.
```{r}
# You can extract model residuals (errors) like this
# and add them to the original data
richness$residuals <- richness_mod$residuals

# That makes it easy to graph the residuals in ggplot!
ggplot(richness, aes(x = residuals)) +
  geom_histogram() +
  facet_wrap(~Survey)
```

Then, we could make predictions from the statistical model to visualize the spatial and temporal patterns we found. Here, we'll just make predictions from the model on the response scale for simplicity (as opposed to the link scale, but that's a different workshop).

```{r}
richness$preds <-  predict(richness_mod, type = "response")
```

Now, we can plot predicted species richness.

```{r}
ggplot(richness, aes(x = Longitude, y = Latitude, color = preds)) +
  geom_point() +
  facet_wrap(~Survey)
```

Wow, that's so cool!!! But, there are a bunch of things we can improve, for example adding a color ramp that's easier to read.

